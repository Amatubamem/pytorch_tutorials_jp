{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sin, cos, pi, floor, exp, log, log10, sqrt, cbrt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:06<00:00, 3966081.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 99385.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:10<00:00, 420842.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 2118551.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# データローダーの作成\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 訓練に際して、可能であればGPU（mps）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else \"cpu\") \n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# modelを定義します\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "_parameters\n",
      "_buffers\n",
      "_non_persistent_buffers_set\n",
      "_backward_pre_hooks\n",
      "_backward_hooks\n",
      "_is_full_backward_hook\n",
      "_forward_hooks\n",
      "_forward_hooks_with_kwargs\n",
      "_forward_pre_hooks\n",
      "_forward_pre_hooks_with_kwargs\n",
      "_state_dict_hooks\n",
      "_state_dict_pre_hooks\n",
      "_load_state_dict_pre_hooks\n",
      "_load_state_dict_post_hooks\n",
      "_modules\n"
     ]
    }
   ],
   "source": [
    "for a in vars(model):\n",
    "# for a in dir(model):\n",
    "#     if a in vars(model):\n",
    "#         continue\n",
    "#     if callable(getattr(model, a)):\n",
    "#         continue\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 損失誤差を計算\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # バックプロパゲーション\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.805927  [    0/60000]\n",
      "loss: 0.813849  [ 6400/60000]\n",
      "loss: 0.730569  [12800/60000]\n",
      "loss: 1.077690  [19200/60000]\n",
      "loss: 0.883708  [25600/60000]\n",
      "loss: 1.031282  [32000/60000]\n",
      "loss: 1.038801  [38400/60000]\n",
      "loss: 1.213971  [44800/60000]\n",
      "loss: 1.004539  [51200/60000]\n",
      "loss: 0.990750  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.015178 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.798586  [    0/60000]\n",
      "loss: 0.808363  [ 6400/60000]\n",
      "loss: 0.724709  [12800/60000]\n",
      "loss: 1.072125  [19200/60000]\n",
      "loss: 0.877799  [25600/60000]\n",
      "loss: 1.026748  [32000/60000]\n",
      "loss: 1.033231  [38400/60000]\n",
      "loss: 1.212337  [44800/60000]\n",
      "loss: 1.001811  [51200/60000]\n",
      "loss: 0.983933  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.015105 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.791623  [    0/60000]\n",
      "loss: 0.803356  [ 6400/60000]\n",
      "loss: 0.719058  [12800/60000]\n",
      "loss: 1.066631  [19200/60000]\n",
      "loss: 0.872718  [25600/60000]\n",
      "loss: 1.022065  [32000/60000]\n",
      "loss: 1.028125  [38400/60000]\n",
      "loss: 1.211096  [44800/60000]\n",
      "loss: 0.999345  [51200/60000]\n",
      "loss: 0.977387  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.015037 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.784932  [    0/60000]\n",
      "loss: 0.798739  [ 6400/60000]\n",
      "loss: 0.713881  [12800/60000]\n",
      "loss: 1.061500  [19200/60000]\n",
      "loss: 0.867299  [25600/60000]\n",
      "loss: 1.018020  [32000/60000]\n",
      "loss: 1.023351  [38400/60000]\n",
      "loss: 1.210259  [44800/60000]\n",
      "loss: 0.996964  [51200/60000]\n",
      "loss: 0.970952  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.014973 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.778601  [    0/60000]\n",
      "loss: 0.794476  [ 6400/60000]\n",
      "loss: 0.709111  [12800/60000]\n",
      "loss: 1.056505  [19200/60000]\n",
      "loss: 0.862306  [25600/60000]\n",
      "loss: 1.013739  [32000/60000]\n",
      "loss: 1.018752  [38400/60000]\n",
      "loss: 1.209128  [44800/60000]\n",
      "loss: 0.994828  [51200/60000]\n",
      "loss: 0.964633  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.014913 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.772603  [    0/60000]\n",
      "loss: 0.790589  [ 6400/60000]\n",
      "loss: 0.704681  [12800/60000]\n",
      "loss: 1.051578  [19200/60000]\n",
      "loss: 0.857304  [25600/60000]\n",
      "loss: 1.009300  [32000/60000]\n",
      "loss: 1.014290  [38400/60000]\n",
      "loss: 1.207715  [44800/60000]\n",
      "loss: 0.992770  [51200/60000]\n",
      "loss: 0.958621  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.014856 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.766858  [    0/60000]\n",
      "loss: 0.786927  [ 6400/60000]\n",
      "loss: 0.700564  [12800/60000]\n",
      "loss: 1.046934  [19200/60000]\n",
      "loss: 0.852400  [25600/60000]\n",
      "loss: 1.004946  [32000/60000]\n",
      "loss: 1.010377  [38400/60000]\n",
      "loss: 1.206617  [44800/60000]\n",
      "loss: 0.990845  [51200/60000]\n",
      "loss: 0.952870  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.014802 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.761463  [    0/60000]\n",
      "loss: 0.783779  [ 6400/60000]\n",
      "loss: 0.696632  [12800/60000]\n",
      "loss: 1.042383  [19200/60000]\n",
      "loss: 0.847527  [25600/60000]\n",
      "loss: 1.000665  [32000/60000]\n",
      "loss: 1.006532  [38400/60000]\n",
      "loss: 1.205615  [44800/60000]\n",
      "loss: 0.988990  [51200/60000]\n",
      "loss: 0.947146  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.014752 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.756385  [    0/60000]\n",
      "loss: 0.780784  [ 6400/60000]\n",
      "loss: 0.693054  [12800/60000]\n",
      "loss: 1.037914  [19200/60000]\n",
      "loss: 0.842837  [25600/60000]\n",
      "loss: 0.996161  [32000/60000]\n",
      "loss: 1.002958  [38400/60000]\n",
      "loss: 1.204795  [44800/60000]\n",
      "loss: 0.987223  [51200/60000]\n",
      "loss: 0.942152  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.014704 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.751511  [    0/60000]\n",
      "loss: 0.777967  [ 6400/60000]\n",
      "loss: 0.689706  [12800/60000]\n",
      "loss: 1.033619  [19200/60000]\n",
      "loss: 0.838471  [25600/60000]\n",
      "loss: 0.991833  [32000/60000]\n",
      "loss: 0.999523  [38400/60000]\n",
      "loss: 1.203562  [44800/60000]\n",
      "loss: 0.985382  [51200/60000]\n",
      "loss: 0.936891  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.014659 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.746867  [    0/60000]\n",
      "loss: 0.775296  [ 6400/60000]\n",
      "loss: 0.686569  [12800/60000]\n",
      "loss: 1.029419  [19200/60000]\n",
      "loss: 0.834048  [25600/60000]\n",
      "loss: 0.987677  [32000/60000]\n",
      "loss: 0.996375  [38400/60000]\n",
      "loss: 1.202736  [44800/60000]\n",
      "loss: 0.983866  [51200/60000]\n",
      "loss: 0.932225  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.014615 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.742229  [    0/60000]\n",
      "loss: 0.772825  [ 6400/60000]\n",
      "loss: 0.683607  [12800/60000]\n",
      "loss: 1.025329  [19200/60000]\n",
      "loss: 0.829798  [25600/60000]\n",
      "loss: 0.983270  [32000/60000]\n",
      "loss: 0.993364  [38400/60000]\n",
      "loss: 1.202105  [44800/60000]\n",
      "loss: 0.982216  [51200/60000]\n",
      "loss: 0.927463  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.014575 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.737816  [    0/60000]\n",
      "loss: 0.770739  [ 6400/60000]\n",
      "loss: 0.680808  [12800/60000]\n",
      "loss: 1.021424  [19200/60000]\n",
      "loss: 0.825532  [25600/60000]\n",
      "loss: 0.979045  [32000/60000]\n",
      "loss: 0.990468  [38400/60000]\n",
      "loss: 1.201231  [44800/60000]\n",
      "loss: 0.980591  [51200/60000]\n",
      "loss: 0.922794  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.014536 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.733626  [    0/60000]\n",
      "loss: 0.768759  [ 6400/60000]\n",
      "loss: 0.678120  [12800/60000]\n",
      "loss: 1.017636  [19200/60000]\n",
      "loss: 0.821375  [25600/60000]\n",
      "loss: 0.975099  [32000/60000]\n",
      "loss: 0.987903  [38400/60000]\n",
      "loss: 1.199865  [44800/60000]\n",
      "loss: 0.979339  [51200/60000]\n",
      "loss: 0.918392  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.014499 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.729506  [    0/60000]\n",
      "loss: 0.766907  [ 6400/60000]\n",
      "loss: 0.675621  [12800/60000]\n",
      "loss: 1.013971  [19200/60000]\n",
      "loss: 0.817224  [25600/60000]\n",
      "loss: 0.971297  [32000/60000]\n",
      "loss: 0.985247  [38400/60000]\n",
      "loss: 1.198615  [44800/60000]\n",
      "loss: 0.977727  [51200/60000]\n",
      "loss: 0.914277  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.014464 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.725508  [    0/60000]\n",
      "loss: 0.765144  [ 6400/60000]\n",
      "loss: 0.673320  [12800/60000]\n",
      "loss: 1.010431  [19200/60000]\n",
      "loss: 0.813131  [25600/60000]\n",
      "loss: 0.967257  [32000/60000]\n",
      "loss: 0.982751  [38400/60000]\n",
      "loss: 1.197495  [44800/60000]\n",
      "loss: 0.976116  [51200/60000]\n",
      "loss: 0.909896  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.014430 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.721565  [    0/60000]\n",
      "loss: 0.763457  [ 6400/60000]\n",
      "loss: 0.671320  [12800/60000]\n",
      "loss: 1.006807  [19200/60000]\n",
      "loss: 0.809331  [25600/60000]\n",
      "loss: 0.963199  [32000/60000]\n",
      "loss: 0.980371  [38400/60000]\n",
      "loss: 1.196328  [44800/60000]\n",
      "loss: 0.974480  [51200/60000]\n",
      "loss: 0.906059  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.014397 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.717745  [    0/60000]\n",
      "loss: 0.761842  [ 6400/60000]\n",
      "loss: 0.669245  [12800/60000]\n",
      "loss: 1.003272  [19200/60000]\n",
      "loss: 0.805384  [25600/60000]\n",
      "loss: 0.959233  [32000/60000]\n",
      "loss: 0.978138  [38400/60000]\n",
      "loss: 1.195053  [44800/60000]\n",
      "loss: 0.972863  [51200/60000]\n",
      "loss: 0.902741  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.014366 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.714126  [    0/60000]\n",
      "loss: 0.760425  [ 6400/60000]\n",
      "loss: 0.667400  [12800/60000]\n",
      "loss: 0.999926  [19200/60000]\n",
      "loss: 0.802374  [25600/60000]\n",
      "loss: 0.955491  [32000/60000]\n",
      "loss: 0.976074  [38400/60000]\n",
      "loss: 1.193778  [44800/60000]\n",
      "loss: 0.971202  [51200/60000]\n",
      "loss: 0.899131  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.014336 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.710609  [    0/60000]\n",
      "loss: 0.759139  [ 6400/60000]\n",
      "loss: 0.665499  [12800/60000]\n",
      "loss: 0.996629  [19200/60000]\n",
      "loss: 0.798478  [25600/60000]\n",
      "loss: 0.951673  [32000/60000]\n",
      "loss: 0.974082  [38400/60000]\n",
      "loss: 1.192467  [44800/60000]\n",
      "loss: 0.970203  [51200/60000]\n",
      "loss: 0.895645  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.014308 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.707059  [    0/60000]\n",
      "loss: 0.757852  [ 6400/60000]\n",
      "loss: 0.663691  [12800/60000]\n",
      "loss: 0.993494  [19200/60000]\n",
      "loss: 0.794383  [25600/60000]\n",
      "loss: 0.948150  [32000/60000]\n",
      "loss: 0.972044  [38400/60000]\n",
      "loss: 1.191275  [44800/60000]\n",
      "loss: 0.968476  [51200/60000]\n",
      "loss: 0.892685  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.014280 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.703858  [    0/60000]\n",
      "loss: 0.756747  [ 6400/60000]\n",
      "loss: 0.661927  [12800/60000]\n",
      "loss: 0.990381  [19200/60000]\n",
      "loss: 0.790562  [25600/60000]\n",
      "loss: 0.944677  [32000/60000]\n",
      "loss: 0.970309  [38400/60000]\n",
      "loss: 1.190127  [44800/60000]\n",
      "loss: 0.966606  [51200/60000]\n",
      "loss: 0.889871  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.014253 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.700695  [    0/60000]\n",
      "loss: 0.755686  [ 6400/60000]\n",
      "loss: 0.660303  [12800/60000]\n",
      "loss: 0.987402  [19200/60000]\n",
      "loss: 0.786780  [25600/60000]\n",
      "loss: 0.941251  [32000/60000]\n",
      "loss: 0.968627  [38400/60000]\n",
      "loss: 1.188676  [44800/60000]\n",
      "loss: 0.965050  [51200/60000]\n",
      "loss: 0.887098  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.014227 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.697635  [    0/60000]\n",
      "loss: 0.754645  [ 6400/60000]\n",
      "loss: 0.658698  [12800/60000]\n",
      "loss: 0.984560  [19200/60000]\n",
      "loss: 0.783118  [25600/60000]\n",
      "loss: 0.938028  [32000/60000]\n",
      "loss: 0.966601  [38400/60000]\n",
      "loss: 1.187244  [44800/60000]\n",
      "loss: 0.963386  [51200/60000]\n",
      "loss: 0.884099  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.014202 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.694631  [    0/60000]\n",
      "loss: 0.753628  [ 6400/60000]\n",
      "loss: 0.657174  [12800/60000]\n",
      "loss: 0.981899  [19200/60000]\n",
      "loss: 0.779588  [25600/60000]\n",
      "loss: 0.934641  [32000/60000]\n",
      "loss: 0.964789  [38400/60000]\n",
      "loss: 1.185752  [44800/60000]\n",
      "loss: 0.961719  [51200/60000]\n",
      "loss: 0.881582  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.014178 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.691680  [    0/60000]\n",
      "loss: 0.752698  [ 6400/60000]\n",
      "loss: 0.655819  [12800/60000]\n",
      "loss: 0.979218  [19200/60000]\n",
      "loss: 0.776030  [25600/60000]\n",
      "loss: 0.931574  [32000/60000]\n",
      "loss: 0.963200  [38400/60000]\n",
      "loss: 1.184191  [44800/60000]\n",
      "loss: 0.960203  [51200/60000]\n",
      "loss: 0.879019  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.014154 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.688840  [    0/60000]\n",
      "loss: 0.751755  [ 6400/60000]\n",
      "loss: 0.654451  [12800/60000]\n",
      "loss: 0.976554  [19200/60000]\n",
      "loss: 0.772594  [25600/60000]\n",
      "loss: 0.928585  [32000/60000]\n",
      "loss: 0.961711  [38400/60000]\n",
      "loss: 1.182667  [44800/60000]\n",
      "loss: 0.958907  [51200/60000]\n",
      "loss: 0.876701  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.014132 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.686127  [    0/60000]\n",
      "loss: 0.750605  [ 6400/60000]\n",
      "loss: 0.653006  [12800/60000]\n",
      "loss: 0.974028  [19200/60000]\n",
      "loss: 0.769278  [25600/60000]\n",
      "loss: 0.925782  [32000/60000]\n",
      "loss: 0.960359  [38400/60000]\n",
      "loss: 1.181178  [44800/60000]\n",
      "loss: 0.957446  [51200/60000]\n",
      "loss: 0.874594  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.014110 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.683479  [    0/60000]\n",
      "loss: 0.749416  [ 6400/60000]\n",
      "loss: 0.651732  [12800/60000]\n",
      "loss: 0.971594  [19200/60000]\n",
      "loss: 0.766121  [25600/60000]\n",
      "loss: 0.923059  [32000/60000]\n",
      "loss: 0.959075  [38400/60000]\n",
      "loss: 1.179666  [44800/60000]\n",
      "loss: 0.955871  [51200/60000]\n",
      "loss: 0.872509  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.014089 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.680923  [    0/60000]\n",
      "loss: 0.748535  [ 6400/60000]\n",
      "loss: 0.650440  [12800/60000]\n",
      "loss: 0.969187  [19200/60000]\n",
      "loss: 0.764012  [25600/60000]\n",
      "loss: 0.920472  [32000/60000]\n",
      "loss: 0.957866  [38400/60000]\n",
      "loss: 1.178094  [44800/60000]\n",
      "loss: 0.954565  [51200/60000]\n",
      "loss: 0.870648  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.014068 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.678339  [    0/60000]\n",
      "loss: 0.747620  [ 6400/60000]\n",
      "loss: 0.648971  [12800/60000]\n",
      "loss: 0.966929  [19200/60000]\n",
      "loss: 0.760939  [25600/60000]\n",
      "loss: 0.917921  [32000/60000]\n",
      "loss: 0.956788  [38400/60000]\n",
      "loss: 1.176664  [44800/60000]\n",
      "loss: 0.953078  [51200/60000]\n",
      "loss: 0.868730  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.014048 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.675895  [    0/60000]\n",
      "loss: 0.746821  [ 6400/60000]\n",
      "loss: 0.647370  [12800/60000]\n",
      "loss: 0.964775  [19200/60000]\n",
      "loss: 0.757917  [25600/60000]\n",
      "loss: 0.915490  [32000/60000]\n",
      "loss: 0.954889  [38400/60000]\n",
      "loss: 1.175499  [44800/60000]\n",
      "loss: 0.951595  [51200/60000]\n",
      "loss: 0.866501  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.014028 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.673536  [    0/60000]\n",
      "loss: 0.746060  [ 6400/60000]\n",
      "loss: 0.645818  [12800/60000]\n",
      "loss: 0.962771  [19200/60000]\n",
      "loss: 0.754906  [25600/60000]\n",
      "loss: 0.913075  [32000/60000]\n",
      "loss: 0.952822  [38400/60000]\n",
      "loss: 1.174010  [44800/60000]\n",
      "loss: 0.950036  [51200/60000]\n",
      "loss: 0.865050  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.014009 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.671254  [    0/60000]\n",
      "loss: 0.745345  [ 6400/60000]\n",
      "loss: 0.644224  [12800/60000]\n",
      "loss: 0.960730  [19200/60000]\n",
      "loss: 0.752098  [25600/60000]\n",
      "loss: 0.910925  [32000/60000]\n",
      "loss: 0.950858  [38400/60000]\n",
      "loss: 1.172479  [44800/60000]\n",
      "loss: 0.948572  [51200/60000]\n",
      "loss: 0.863576  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.013991 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.668884  [    0/60000]\n",
      "loss: 0.744503  [ 6400/60000]\n",
      "loss: 0.642731  [12800/60000]\n",
      "loss: 0.958920  [19200/60000]\n",
      "loss: 0.749456  [25600/60000]\n",
      "loss: 0.908784  [32000/60000]\n",
      "loss: 0.948718  [38400/60000]\n",
      "loss: 1.171147  [44800/60000]\n",
      "loss: 0.947089  [51200/60000]\n",
      "loss: 0.862278  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.013973 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.666605  [    0/60000]\n",
      "loss: 0.743486  [ 6400/60000]\n",
      "loss: 0.641206  [12800/60000]\n",
      "loss: 0.957117  [19200/60000]\n",
      "loss: 0.747001  [25600/60000]\n",
      "loss: 0.906784  [32000/60000]\n",
      "loss: 0.946880  [38400/60000]\n",
      "loss: 1.169785  [44800/60000]\n",
      "loss: 0.945521  [51200/60000]\n",
      "loss: 0.860920  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.013955 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.664309  [    0/60000]\n",
      "loss: 0.742540  [ 6400/60000]\n",
      "loss: 0.639723  [12800/60000]\n",
      "loss: 0.955401  [19200/60000]\n",
      "loss: 0.744459  [25600/60000]\n",
      "loss: 0.904869  [32000/60000]\n",
      "loss: 0.945041  [38400/60000]\n",
      "loss: 1.168290  [44800/60000]\n",
      "loss: 0.943944  [51200/60000]\n",
      "loss: 0.859589  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.013938 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.662083  [    0/60000]\n",
      "loss: 0.741933  [ 6400/60000]\n",
      "loss: 0.638333  [12800/60000]\n",
      "loss: 0.953687  [19200/60000]\n",
      "loss: 0.741880  [25600/60000]\n",
      "loss: 0.902511  [32000/60000]\n",
      "loss: 0.943265  [38400/60000]\n",
      "loss: 1.166683  [44800/60000]\n",
      "loss: 0.941211  [51200/60000]\n",
      "loss: 0.858119  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.013920 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.659961  [    0/60000]\n",
      "loss: 0.741072  [ 6400/60000]\n",
      "loss: 0.637004  [12800/60000]\n",
      "loss: 0.952011  [19200/60000]\n",
      "loss: 0.739523  [25600/60000]\n",
      "loss: 0.900720  [32000/60000]\n",
      "loss: 0.941558  [38400/60000]\n",
      "loss: 1.165343  [44800/60000]\n",
      "loss: 0.939675  [51200/60000]\n",
      "loss: 0.856778  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.013904 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.657848  [    0/60000]\n",
      "loss: 0.740221  [ 6400/60000]\n",
      "loss: 0.635733  [12800/60000]\n",
      "loss: 0.950405  [19200/60000]\n",
      "loss: 0.737359  [25600/60000]\n",
      "loss: 0.899141  [32000/60000]\n",
      "loss: 0.939614  [38400/60000]\n",
      "loss: 1.163904  [44800/60000]\n",
      "loss: 0.937463  [51200/60000]\n",
      "loss: 0.855531  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.013888 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.655780  [    0/60000]\n",
      "loss: 0.739434  [ 6400/60000]\n",
      "loss: 0.634385  [12800/60000]\n",
      "loss: 0.948750  [19200/60000]\n",
      "loss: 0.735147  [25600/60000]\n",
      "loss: 0.897509  [32000/60000]\n",
      "loss: 0.938012  [38400/60000]\n",
      "loss: 1.162876  [44800/60000]\n",
      "loss: 0.936082  [51200/60000]\n",
      "loss: 0.854411  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.013872 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.653759  [    0/60000]\n",
      "loss: 0.738599  [ 6400/60000]\n",
      "loss: 0.633044  [12800/60000]\n",
      "loss: 0.947148  [19200/60000]\n",
      "loss: 0.732900  [25600/60000]\n",
      "loss: 0.896006  [32000/60000]\n",
      "loss: 0.936329  [38400/60000]\n",
      "loss: 1.161479  [44800/60000]\n",
      "loss: 0.934597  [51200/60000]\n",
      "loss: 0.853440  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.013857 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.651878  [    0/60000]\n",
      "loss: 0.737648  [ 6400/60000]\n",
      "loss: 0.631670  [12800/60000]\n",
      "loss: 0.945578  [19200/60000]\n",
      "loss: 0.730556  [25600/60000]\n",
      "loss: 0.894189  [32000/60000]\n",
      "loss: 0.934127  [38400/60000]\n",
      "loss: 1.160312  [44800/60000]\n",
      "loss: 0.933156  [51200/60000]\n",
      "loss: 0.852469  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.013841 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.650094  [    0/60000]\n",
      "loss: 0.736864  [ 6400/60000]\n",
      "loss: 0.630457  [12800/60000]\n",
      "loss: 0.944113  [19200/60000]\n",
      "loss: 0.728539  [25600/60000]\n",
      "loss: 0.892648  [32000/60000]\n",
      "loss: 0.932729  [38400/60000]\n",
      "loss: 1.158863  [44800/60000]\n",
      "loss: 0.931735  [51200/60000]\n",
      "loss: 0.851578  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.013827 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.648344  [    0/60000]\n",
      "loss: 0.736069  [ 6400/60000]\n",
      "loss: 0.629236  [12800/60000]\n",
      "loss: 0.942714  [19200/60000]\n",
      "loss: 0.726493  [25600/60000]\n",
      "loss: 0.891169  [32000/60000]\n",
      "loss: 0.931300  [38400/60000]\n",
      "loss: 1.157708  [44800/60000]\n",
      "loss: 0.930313  [51200/60000]\n",
      "loss: 0.850580  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.013812 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.646562  [    0/60000]\n",
      "loss: 0.735231  [ 6400/60000]\n",
      "loss: 0.627990  [12800/60000]\n",
      "loss: 0.941333  [19200/60000]\n",
      "loss: 0.724701  [25600/60000]\n",
      "loss: 0.889599  [32000/60000]\n",
      "loss: 0.929881  [38400/60000]\n",
      "loss: 1.156216  [44800/60000]\n",
      "loss: 0.928992  [51200/60000]\n",
      "loss: 0.849815  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.013798 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.644968  [    0/60000]\n",
      "loss: 0.734387  [ 6400/60000]\n",
      "loss: 0.626721  [12800/60000]\n",
      "loss: 0.939952  [19200/60000]\n",
      "loss: 0.723147  [25600/60000]\n",
      "loss: 0.887869  [32000/60000]\n",
      "loss: 0.928638  [38400/60000]\n",
      "loss: 1.154829  [44800/60000]\n",
      "loss: 0.927641  [51200/60000]\n",
      "loss: 0.849080  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.013784 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.643318  [    0/60000]\n",
      "loss: 0.733609  [ 6400/60000]\n",
      "loss: 0.625550  [12800/60000]\n",
      "loss: 0.938610  [19200/60000]\n",
      "loss: 0.721251  [25600/60000]\n",
      "loss: 0.886268  [32000/60000]\n",
      "loss: 0.927353  [38400/60000]\n",
      "loss: 1.153395  [44800/60000]\n",
      "loss: 0.926300  [51200/60000]\n",
      "loss: 0.848401  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.013770 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.641671  [    0/60000]\n",
      "loss: 0.732779  [ 6400/60000]\n",
      "loss: 0.624400  [12800/60000]\n",
      "loss: 0.937209  [19200/60000]\n",
      "loss: 0.719342  [25600/60000]\n",
      "loss: 0.884694  [32000/60000]\n",
      "loss: 0.926187  [38400/60000]\n",
      "loss: 1.151870  [44800/60000]\n",
      "loss: 0.924919  [51200/60000]\n",
      "loss: 0.847584  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.013756 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.639719  [    0/60000]\n",
      "loss: 0.731984  [ 6400/60000]\n",
      "loss: 0.623284  [12800/60000]\n",
      "loss: 0.935859  [19200/60000]\n",
      "loss: 0.717547  [25600/60000]\n",
      "loss: 0.883293  [32000/60000]\n",
      "loss: 0.924906  [38400/60000]\n",
      "loss: 1.150393  [44800/60000]\n",
      "loss: 0.923489  [51200/60000]\n",
      "loss: 0.846265  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.013743 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model0913.pth\")\n",
    "print(\"saved to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model0913.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Coat\", Actual: \"Coat\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[10][0], test_data[10][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
